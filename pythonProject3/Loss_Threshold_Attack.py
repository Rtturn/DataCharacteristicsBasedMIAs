import tensorflow as tf
from dataLoader import *
from tensorflow.keras.models import load_model
import math
from BlindMIUtil import evaluate_attack
import sys
from  data_construct import loadData_cifar100
from tensorflow.python.client import device_lib

os.environ['CUDA_VISIBLE_DEVICES'] = '0'
tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)

DATA_NAME = sys.argv[1] if len(sys.argv) > 1 else "imagenet"
TARGET_MODEL_GENRE = sys.argv[2] if len(sys.argv) > 2 else "ResNet50"
SHADOW_MODEL_GENRE = sys.argv[3] if len(sys.argv) > 2 else "VGG16"
NN_ATTACK_WEIGHTS_PATH = "weights/NN_Attack/NN_Attack_{}_{}.hdf5".format(DATA_NAME, SHADOW_MODEL_GENRE)
TARGET_WEIGHTS_PATH = "weights/Target/{}_{}.hdf5".format(DATA_NAME, TARGET_MODEL_GENRE)
SHADOW_WEIGHTS_PATH = "weights/BlackShadow/{}_{}.hdf5".format(DATA_NAME, SHADOW_MODEL_GENRE)

(x_train_tar, y_train_tar), (x_test_tar, y_test_tar), m_true = loadData_cifar100()
Target_Model = load_model(TARGET_WEIGHTS_PATH)

def loadData_cifar10(filename):
    '''
    Attck the target with BLINDMI-DIFF-W, BLINDMI-DIFF with gernerated non-member.
    The non-member is generated by randomly chosen data and the number is 20 by default.
    If the data has been shuffled, please directly remove the process of shuffling.
    :param target_model: the model that will be attacked
    :param x_: the data that target model may used for trainisng
    :param y_true: the label of x_
    :param m_true: one of 0 and 1, which represents each of x_ has been trained or not.
    :param non_Mem_Generator: the method to generate the non-member data. The default non-member generator
    is Sobel.
    :return:  Tensor arrays of results
    '''
    (x_train_tar, y_train_tar), (x_test_tar, y_test_tar), m_true = globals()['load_' + DATA_NAME]('TargetModel')
    x_=np.r_[x_train_tar,x_test_tar]
    y_true=np.r_[y_train_tar,y_test_tar]
    target_model = load_model(TARGET_WEIGHTS_PATH)

    y_pred=target_model.predict(x_)
    m,n=np.shape(y_pred)
    y_result=np.zeros((m,n))
    correct_index=[]
    correct_label=[]
    correct_pred=[]
    incorrect_index=[]
    incorrect_label=[]
    incorrect_pred=[]
    for i in range(m):
        interval=list(y_pred[i])
        index=interval.index(max(interval))
        y_result[i][index]=1
        true=list(y_true[i])
        true_index=true.index(max(true))
        if index==true_index:
            correct_index.append(i)
            correct_label.append(y_true[i])
            correct_pred.append(y_pred[i])
        else:
            incorrect_index.append(i)
            incorrect_label.append(y_true[i])
            incorrect_pred.append(y_pred[i])
    correct_pred=tf.convert_to_tensor(correct_pred)
    incorrect_pred=tf.convert_to_tensor(incorrect_pred)
    correct=tf.convert_to_tensor(np.c_[correct_pred[y_true[correct_index].astype(bool)],
                                        np.sort(correct_pred, axis=1)[:, ::-1][:, :2]])
    incorrect=tf.convert_to_tensor(np.c_[incorrect_pred[y_true[incorrect_index].astype(bool)],
                                        np.sort(incorrect_pred, axis=1)[:, ::-1][:, :2]])
#    incorrect_read=pd.DataFrame(incorrect_index)
#    incorrect_read.to_excel('incorrect.xlsx')
    mix = np.c_[y_pred[y_true.astype(bool)], np.sort(y_pred, axis=1)[:, ::-1][:, :2]]  #所有数据变换后的结果
    mix=mix.tolist()
    for i in range(m):
        mix[i].append(i)
        mix[i].append(m_true[i])
    mix=tf.convert_to_tensor(mix)
    tf.random.set_seed(1)
    nonMem_index =[ 8669 ,14910 , 8474 , 3386, 14747 , 6521 , 6333 ,16387  , 864  ,6828 ,16821  ,5706,3137,  9035, 15305 , 5487 , 6482 , 9644 ,13005 , 2190]
    #nonMem_index = np.random.randint(0, x_.shape[0], size=20)  # 随机生成
    Mem_dataset=[]
    Mem_index=[]
    for i in range(m):
        if m_true[i]==1:
            Mem_dataset.append(x_[i])
            Mem_index.append(i)
    Mem_dataset=tf.convert_to_tensor(Mem_dataset)
    Mem_pred=target_model.predict(Mem_dataset)
    Mem=tf.convert_to_tensor(np.c_[Mem_pred[y_true[Mem_index].astype(bool)],
                                        np.sort(Mem_pred, axis=1)[:, ::-1][:, :2]])
    tf.random.set_seed(1)
    data = tf.data.Dataset.from_tensor_slices((mix, m_true)).shuffle(buffer_size=x_.shape[0]).\
        batch(20).prefetch(tf.data.experimental.AUTOTUNE)  #切分mix为20000个10列的tensor，每个数据集有20个样本

    idx=pd.read_excel(filename)
    idx = np.array(idx)[:]
    m=len(idx)*20
    x_c = tf.constant(0, shape=(m, 32, 32, 3))
    x_c = np.array(x_)
    y_c = np.ones((m, 200))
    m_c = np.ones(m)
    i = 0
    j = 0
    count_member=0

    for (mix_batch, m_true_batch) in data:  #min_batch:x  m_true_batch:是否为成员
        if j in idx:
            for k in range(20):
                p=int(mix_batch[k][-2])
                x_c[i]=x_[p]
                y_c[i]=y_true[p]
                m_c[i]=int(m_true_batch[k])
                i+=1
                count_member+=int(mix_batch[k][-1])
        j+=1
    x_train=[]
    x_test=[]
    y_train=[]
    y_test=[]
    for i in range(m):
        if m_c[i]==1:
            x_train.append(x_c[i])
            y_train.append(y_c[i])
        else:
            x_test.append(x_c[i])
            y_test.append(y_c[i])
    x_train=tf.convert_to_tensor(x_train)
    x_test=tf.convert_to_tensor(x_test)
    y_train=np.array(y_train)
    y_train=tf.convert_to_tensor(y_train)
    y_test=np.array(y_test)
    y_test=tf.convert_to_tensor(y_test)
    m_true=np.zeros(m)
    print(count_member)
    m_true[:count_member]=1
    return (x_train,y_train),(x_test,y_test),m_true
def loss_threshold_attack(x_, y_true):
    (x_train_sha, y_train_sha), _, m_train = globals()['load_' + DATA_NAME]('ShadowModel')
    Shadow_Model = load_model(SHADOW_WEIGHTS_PATH)
    avg_loss = Shadow_Model.evaluate(x_train_sha, y_train_sha)[0]

    x_loss = np.asarray([-math.log(y_pred) if y_pred > 0 else y_pred+1e-50 for y_pred in Target_Model.
                        predict(x_)[y_true.astype(bool)]])
    m_pred = np.where(x_loss <= avg_loss, 1, 0)
    return m_pred


'''
y_pred=y_pred[10000:]
y_true=y_true[10000:]
index=[]
for i in range(10000):
    interval = list(y_pred[i])
    index1 = interval.index(max(interval))
    true = list(y_true[i])
    true_index = true.index(max(true))
    if index1 != true_index:
        index.append(i)
index=pd.DataFrame(index)
index.to_excel('NN_incorrect.xlsx')
'''
file=open('construct1/data_file_imagenet.txt')
for lines in file:
    filename=lines.strip()
    (x_train_tar, y_train_tar), (x_test_tar, y_test_tar), m_true = loadData_cifar10(filename)
    m_pred = loss_threshold_attack(np.r_[x_train_tar, x_test_tar], np.r_[y_train_tar, y_test_tar])
    for i in range(len(m_pred)):
        if m_pred[i] >= 0.5:
            m_pred[i] = 1
        else:
            m_pred[i] = 0
    y_pred = Target_Model.predict(np.r_[x_train_tar, x_test_tar])
    m, n = np.shape(y_pred)
    y_true = np.r_[y_train_tar, y_test_tar]
    count_correct = 0
    count_error = 0
    correct_member = 0
    correct_nonmember = 0
    incorrect_member = 0
    incorrect_nonmember = 0
    for i in range(m):
        interval = list(y_pred[i])
        index = interval.index(max(interval))
        true = list(y_true[i])
        true_index = true.index(max(true))
        if index == true_index:
            count_correct += 1
            if m_true[i] == 1:
                correct_member += 1
            else:
                correct_nonmember += 1
        else:
            count_error += 1
            if m_true[i] == 1:
                incorrect_member += 1
            else:
                incorrect_nonmember += 1
    nonmember_in_mem = 0
    nonmember_correct_in_mem = 0
    for i in range(m):
        if m_true[i] == 0 and m_pred[i] == 1:
            nonmember_in_mem += 1
            interval = list(y_pred[i])
            index = interval.index(max(interval))
            true = list(y_true[i])
            true_index = true.index(max(true))
            if index == true_index:
                nonmember_correct_in_mem += 1
    save_file=open('construct1/result.txt',mode='a+')
    save_file.write(str(filename)+'\n')
    save_file.writelines('count_correct:')
    save_file.write(str(count_correct)+'\n')
    save_file.writelines('count_error:')
    save_file.write(str(count_error)+'\n')
    save_file.writelines('member:')
    save_file.write(str(sum(m_true))+'\n')
    save_file.writelines('nonmember:')
    save_file.write(str(m - sum(m_true))+'\n')
    save_file.writelines('correct_member:')
    save_file.write(str(correct_member)+'\n')
    save_file.writelines('incorrect_member:')
    save_file.write(str(incorrect_member)+'\n')
    save_file.writelines('correct_nonmember:')
    save_file.write(str(correct_nonmember)+'\n')
    save_file.writelines('incorrect_nonmember:')
    save_file.write(str(incorrect_nonmember)+'\n')
    save_file.writelines('precision:')
    save_file.write(str(count_correct / m)+'\n')
    save_file.writelines('nonmember_in_mem:')
    save_file.write(str(nonmember_in_mem)+'\n')
    save_file.writelines('nonmember_correct_in_mem:')
    save_file.write(str(nonmember_correct_in_mem)+'\n')
    save_file.writelines('total_member:')
    save_file.write(str(sum(m_pred))+'\n')
    save_file.writelines('error_ratio:')
    save_file.write(str(nonmember_in_mem / sum(m_pred)*100)+'%'+'\n')
    save_file.writelines('nonmember_in_mem/nonmember:')
    save_file.write(str(nonmember_in_mem / (m - sum(m_true))*100)+'%'+'\n')
    save_file.write(str(evaluate_attack(m_true, m_pred))+'\n')
    save_file.close()
    gc.collect()
