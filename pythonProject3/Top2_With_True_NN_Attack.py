from dataLoader import *
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import metrics
from tensorflow.keras.models import load_model
from tensorflow.keras.layers import Dropout, Dense, Activation
from tensorflow.keras.callbacks import ModelCheckpoint
import sys
from data_construct import *

os.environ['CUDA_VISIBLE_DEVICES'] = '0'
tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)
DATA_NAME = sys.argv[1] if len(sys.argv) > 1 else "CH_MNIST"
TARGET_MODEL_GENRE = sys.argv[2] if len(sys.argv) > 2 else "ResNet50"
SHADOW_MODEL_GENRE = sys.argv[3] if len(sys.argv) > 3 else "VGG16"
EPOCHS = 40
BATCH_SIZE = 64
NUM_CLASSES = 1
LEARNING_RATE = 5e-5
NN_ATTACK_WEIGHTS_PATH = "weights/NN_Attack/BlackBox/Top2_True_NN_Attack_{}_{}.hdf5".format(DATA_NAME, SHADOW_MODEL_GENRE)
TARGET_WEIGHTS_PATH = "weights/Target/{}_{}.hdf5".format(DATA_NAME, TARGET_MODEL_GENRE)
SHADOW_WEIGHTS_PATH = "weights/BlackShadow/{}_{}.hdf5".format(DATA_NAME, SHADOW_MODEL_GENRE)

(x_train_sha, y_train_sha), (x_test_sha, y_test_sha), m_train = globals()['load_' + DATA_NAME]('ShadowModel')
Shadow_Model = load_model(SHADOW_WEIGHTS_PATH)
con_Score_Sha = Shadow_Model.predict(np.r_[x_train_sha, x_test_sha])
c_train = np.c_[con_Score_Sha[np.r_[y_train_sha, y_test_sha].astype(bool)], np.sort(con_Score_Sha, axis=1)[:, ::-1][:, :2]]

def loadData_cifar10(filename):
    '''
    Attck the target with BLINDMI-DIFF-W, BLINDMI-DIFF with gernerated non-member.
    The non-member is generated by randomly chosen data and the number is 20 by default.
    If the data has been shuffled, please directly remove the process of shuffling.
    :param target_model: the model that will be attacked
    :param x_: the data that target model may used for trainisng
    :param y_true: the label of x_
    :param m_true: one of 0 and 1, which represents each of x_ has been trained or not.
    :param non_Mem_Generator: the method to generate the non-member data. The default non-member generator
    is Sobel.
    :return:  Tensor arrays of results
    '''
    (x_train_tar, y_train_tar), (x_test_tar, y_test_tar), m_true = globals()['load_' + DATA_NAME]('TargetModel')
    x_=np.r_[x_train_tar,x_test_tar]
    y_true=np.r_[y_train_tar,y_test_tar]
    target_model = load_model(TARGET_WEIGHTS_PATH)

    y_pred=target_model.predict(x_)
    m,n=np.shape(y_pred)
    y_result=np.zeros((m,n))
    correct_index=[]
    correct_label=[]
    correct_pred=[]
    incorrect_index=[]
    incorrect_label=[]
    incorrect_pred=[]
    for i in range(m):
        interval=list(y_pred[i])
        index=interval.index(max(interval))
        y_result[i][index]=1
        true=list(y_true[i])
        true_index=true.index(max(true))
        if index==true_index:
            correct_index.append(i)
            correct_label.append(y_true[i])
            correct_pred.append(y_pred[i])
        else:
            incorrect_index.append(i)
            incorrect_label.append(y_true[i])
            incorrect_pred.append(y_pred[i])
    correct_pred=tf.convert_to_tensor(correct_pred)
    incorrect_pred=tf.convert_to_tensor(incorrect_pred)
    correct=tf.convert_to_tensor(np.c_[correct_pred[y_true[correct_index].astype(bool)],
                                        np.sort(correct_pred, axis=1)[:, ::-1][:, :2]])
    incorrect=tf.convert_to_tensor(np.c_[incorrect_pred[y_true[incorrect_index].astype(bool)],
                                        np.sort(incorrect_pred, axis=1)[:, ::-1][:, :2]])
#    incorrect_read=pd.DataFrame(incorrect_index)
#    incorrect_read.to_excel('incorrect.xlsx')
    mix = np.c_[y_pred[y_true.astype(bool)], np.sort(y_pred, axis=1)[:, ::-1][:, :2]]  #所有数据变换后的结果
    mix=mix.tolist()
    for i in range(m):
        mix[i].append(i)
        mix[i].append(m_true[i])
    mix=tf.convert_to_tensor(mix)
    tf.random.set_seed(1)
    nonMem_index =[ 8669 ,14910 , 8474 , 3386, 14747 , 6521 , 6333 ,16387  , 864  ,6828 ,16821  ,5706,3137,  9035, 15305 , 5487 , 6482 , 9644 ,13005 , 2190]
    #nonMem_index = np.random.randint(0, x_.shape[0], size=20)  # 随机生成
    Mem_dataset=[]
    Mem_index=[]
    for i in range(m):
        if m_true[i]==1:
            Mem_dataset.append(x_[i])
            Mem_index.append(i)
    Mem_dataset=tf.convert_to_tensor(Mem_dataset)
    Mem_pred=target_model.predict(Mem_dataset)
    Mem=tf.convert_to_tensor(np.c_[Mem_pred[y_true[Mem_index].astype(bool)],
                                        np.sort(Mem_pred, axis=1)[:, ::-1][:, :2]])
    tf.random.set_seed(2)
    data = tf.data.Dataset.from_tensor_slices((mix, m_true)).shuffle(buffer_size=x_.shape[0]).\
        batch(20).prefetch(tf.data.experimental.AUTOTUNE)  #切分mix为20000个10列的tensor，每个数据集有20个样本

    idx=pd.read_excel(filename)
    idx = np.array(idx)[:]
    m=len(idx)*20
    x_c = tf.constant(0, shape=(m, 32, 32, 3))
    x_c = np.array(x_)
    y_c = np.ones((m, 8))
    m_c = np.ones(m)
    i = 0
    j = 0
    count_member=0

    for (mix_batch, m_true_batch) in data:  #min_batch:x  m_true_batch:是否为成员
        if j in idx:
            for k in range(20):
                p=int(mix_batch[k][-2])
                x_c[i]=x_[p]
                y_c[i]=y_true[p]
                m_c[i]=int(m_true_batch[k])
                i+=1
                count_member+=int(mix_batch[k][-1])
        j+=1
    x_train=[]
    x_test=[]
    y_train=[]
    y_test=[]
    for i in range(m):
        if m_c[i]==1:
            x_train.append(x_c[i])
            y_train.append(y_c[i])
        else:
            x_test.append(x_c[i])
            y_test.append(y_c[i])
    x_train=tf.convert_to_tensor(x_train)
    x_test=tf.convert_to_tensor(x_test)
    y_train=np.array(y_train)
    y_train=tf.convert_to_tensor(y_train)
    y_test=np.array(y_test)
    y_test=tf.convert_to_tensor(y_test)
    m_true=np.zeros(m)
    print(count_member)
    m_true[:count_member]=1
    return (x_train,y_train),(x_test,y_test),m_true

def create_attack_model(input_dim, num_classes=NUM_CLASSES):
    model = tf.keras.Sequential([
        Dense(512, input_dim=input_dim, activation='relu'),
        Dropout(0.2),
        Dense(256, activation='relu'),
        Dropout(0.2),
        Dense(128, activation='relu'),
        Dense(num_classes),
        Activation('sigmoid')
    ])
    model.summary()
    return model

def train(model, x_train, y_train):
    model.compile(loss='binary_crossentropy',
                  optimizer=keras.optimizers.Adam(lr=LEARNING_RATE),
                  metrics=[metrics.BinaryAccuracy(), metrics.Precision(), metrics.Recall()])
    checkpoint = ModelCheckpoint(NN_ATTACK_WEIGHTS_PATH, monitor='precision', verbose=1, save_best_only=True,
                                 mode='max')
    model.fit(x_train, y_train,
              epochs=EPOCHS,
              batch_size=BATCH_SIZE,
              callbacks=[checkpoint])

def evaluate(x_test, y_test):
    model = keras.models.load_model(NN_ATTACK_WEIGHTS_PATH)

    loss, accuracy, precision, recall = model.evaluate(x_test, y_test, verbose=1)
    F1_Score = 2 * (precision * recall) / (precision + recall)
    return ('loss:%.4f accuracy:%.4f precision:%.4f recall:%.4f F1_Score:%.4f'
          % (loss, accuracy, precision, recall, F1_Score))

file=open('construct1/data_file_chmnist.txt')
for lines in file:
    model = keras.models.load_model(NN_ATTACK_WEIGHTS_PATH)
    Target_Model = load_model(TARGET_WEIGHTS_PATH)
    attackModel = create_attack_model(c_train.shape[1])
    train(attackModel, c_train, m_train)
    filename=lines.strip()
    (x_train_tar, y_train_tar), (x_test_tar, y_test_tar), m_test = loadData_cifar10(filename)
    con_Score_Tar = Target_Model.predict(np.r_[x_train_tar, x_test_tar])
    c_test = np.c_[
        con_Score_Tar[np.r_[y_train_tar, y_test_tar].astype(bool)], np.sort(con_Score_Tar, axis=1)[:, ::-1][:, :2]]
    m_true=m_test
    m_pred =model.predict(c_test)
    for i in range(len(m_pred)):
        if m_pred[i] >= 0.5:
            m_pred[i] = 1
        else:
            m_pred[i] = 0
    y_pred = Target_Model.predict(np.r_[x_train_tar, x_test_tar])
    m, n = np.shape(y_pred)
    y_true = np.r_[y_train_tar, y_test_tar]
    count_correct = 0
    count_error = 0
    correct_member = 0
    correct_nonmember = 0
    incorrect_member = 0
    incorrect_nonmember = 0
    for i in range(m):
        interval = list(y_pred[i])
        index = interval.index(max(interval))
        true = list(y_true[i])
        true_index = true.index(max(true))
        if index == true_index:
            count_correct += 1
            if m_true[i] == 1:
                correct_member += 1
            else:
                correct_nonmember += 1
        else:
            count_error += 1
            if m_true[i] == 1:
                incorrect_member += 1
            else:
                incorrect_nonmember += 1
    nonmember_in_mem = 0
    nonmember_correct_in_mem = 0
    for i in range(m):
        if m_true[i] == 0 and m_pred[i] == 1:
            nonmember_in_mem += 1
            interval = list(y_pred[i])
            index = interval.index(max(interval))
            true = list(y_true[i])
            true_index = true.index(max(true))
            if index == true_index:
                nonmember_correct_in_mem += 1
    save_file=open('construct1/result.txt',mode='a+')
    save_file.write(str(filename)+'\n')
    save_file.writelines('count_correct:')
    save_file.write(str(count_correct)+'\n')
    save_file.writelines('count_error:')
    save_file.write(str(count_error)+'\n')
    save_file.writelines('member:')
    save_file.write(str(sum(m_true))+'\n')
    save_file.writelines('nonmember:')
    save_file.write(str(m - sum(m_true))+'\n')
    save_file.writelines('correct_member:')
    save_file.write(str(correct_member)+'\n')
    save_file.writelines('incorrect_member:')
    save_file.write(str(incorrect_member)+'\n')
    save_file.writelines('correct_nonmember:')
    save_file.write(str(correct_nonmember)+'\n')
    save_file.writelines('incorrect_nonmember:')
    save_file.write(str(incorrect_nonmember)+'\n')
    save_file.writelines('precision:')
    save_file.write(str(count_correct / m)+'\n')
    save_file.writelines('nonmember_in_mem:')
    save_file.write(str(nonmember_in_mem)+'\n')
    save_file.writelines('nonmember_correct_in_mem:')
    save_file.write(str(nonmember_correct_in_mem)+'\n')
    save_file.writelines('total_member:')
    save_file.write(str(float(sum(m_pred)))+'\n')
    save_file.writelines('error_ratio:')
    save_file.write(str(float(nonmember_in_mem / sum(m_pred)*100))+'%'+'\n')
    save_file.writelines('nonmember_in_mem/nonmember:')
    save_file.write(str(nonmember_in_mem / (m - sum(m_true))*100)+'%'+'\n')
    save_file.write(str(evaluate(c_test, m_test))+'\n')
    save_file.close()
    gc.collect()

