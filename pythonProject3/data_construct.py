from BlindMIUtil import *
from dataLoader import *
import tensorflow as tf
from tensorflow.keras.models import load_model
import sys
import pandas as pd
import scipy.io as io

def loadData_cifar100():
    '''
    Attck the target with BLINDMI-DIFF-W, BLINDMI-DIFF with gernerated non-member.
    The non-member is generated by randomly chosen data and the number is 20 by default.
    If the data has been shuffled, please directly remove the process of shuffling.
    :param target_model: the model that will be attacked
    :param x_: the data that target model may used for trainisng
    :param y_true: the label of x_
    :param m_true: one of 0 and 1, which represents each of x_ has been trained or not.
    :param non_Mem_Generator: the method to generate the non-member data. The default non-member generator
    is Sobel.
    :return:  Tensor arrays of results
    '''
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)
    DATA_NAME = sys.argv[1] if len(sys.argv) > 1 else "CIFAR"
    TARGET_MODEL_GENRE = sys.argv[2] if len(sys.argv) > 2 else "ResNet50"
    TARGET_WEIGHTS_PATH = "weights/Target/{}_{}.hdf5".format(DATA_NAME, TARGET_MODEL_GENRE)

    (x_train_tar, y_train_tar), (x_test_tar, y_test_tar), m_true = globals()['load_' + DATA_NAME]('TargetModel')
    x_=np.r_[x_train_tar,x_test_tar]
    y_true=np.r_[y_train_tar,y_test_tar]
    target_model = load_model(TARGET_WEIGHTS_PATH)

    y_pred=target_model.predict(x_)
    m,n=np.shape(y_pred)
    y_result=np.zeros((m,n))
    correct_index=[]
    correct_label=[]
    correct_pred=[]
    incorrect_index=[]
    incorrect_label=[]
    incorrect_pred=[]
    for i in range(m):
        interval=list(y_pred[i])
        index=interval.index(max(interval))
        y_result[i][index]=1
        true=list(y_true[i])
        true_index=true.index(max(true))
        if index==true_index:
            correct_index.append(i)
            correct_label.append(y_true[i])
            correct_pred.append(y_pred[i])
        else:
            incorrect_index.append(i)
            incorrect_label.append(y_true[i])
            incorrect_pred.append(y_pred[i])
    correct_pred=tf.convert_to_tensor(correct_pred)
    incorrect_pred=tf.convert_to_tensor(incorrect_pred)
    correct=tf.convert_to_tensor(np.c_[correct_pred[y_true[correct_index].astype(bool)],
                                        np.sort(correct_pred, axis=1)[:, ::-1][:, :2]])
    incorrect=tf.convert_to_tensor(np.c_[incorrect_pred[y_true[incorrect_index].astype(bool)],
                                        np.sort(incorrect_pred, axis=1)[:, ::-1][:, :2]])
#    incorrect_read=pd.DataFrame(incorrect_index)
#    incorrect_read.to_excel('incorrect.xlsx')
    mix = np.c_[y_pred[y_true.astype(bool)], np.sort(y_pred, axis=1)[:, ::-1][:, :2]]  #所有数据变换后的结果
    mix=mix.tolist()
    for i in range(m):
        mix[i].append(i)
        mix[i].append(m_true[i])
    mix=tf.convert_to_tensor(mix)
    tf.random.set_seed(1)
    nonMem_index =[ 8669 ,14910 , 8474 , 3386, 14747 , 6521 , 6333 ,16387  , 864  ,6828 ,16821  ,5706,3137,  9035, 15305 , 5487 , 6482 , 9644 ,13005 , 2190]
    #nonMem_index = np.random.randint(0, x_.shape[0], size=20)  # 随机生成
    Mem_dataset=[]
    Mem_index=[]
    for i in range(m):
        if m_true[i]==1:
            Mem_dataset.append(x_[i])
            Mem_index.append(i)
    Mem_dataset=tf.convert_to_tensor(Mem_dataset)
    Mem_pred=target_model.predict(Mem_dataset)
    Mem=tf.convert_to_tensor(np.c_[Mem_pred[y_true[Mem_index].astype(bool)],
                                        np.sort(Mem_pred, axis=1)[:, ::-1][:, :2]])
    tf.random.set_seed(2)
    data = tf.data.Dataset.from_tensor_slices((mix, m_true)).shuffle(buffer_size=x_.shape[0]).\
        batch(20).prefetch(tf.data.experimental.AUTOTUNE)  #切分mix为20000个10列的tensor，每个数据集有20个样本

    idx=pd.read_excel('construct/cifar100_c_u1.xlsx')
    idx = np.array(idx)[:]
    m=len(idx)*20
    x_c = tf.constant(0, shape=(m, 32, 32, 3))
    x_c = np.array(x_)
    y_c = np.ones((m, 100))
    m_c = np.ones(m)
    i = 0
    j = 0
    count_member=0

    for (mix_batch, m_true_batch) in data:  #min_batch:x  m_true_batch:是否为成员
        if j in idx:
            for k in range(20):
                p=int(mix_batch[k][-2])
                x_c[i]=x_[p]
                y_c[i]=y_true[p]
                m_c[i]=int(m_true_batch[k])
                i+=1
                count_member+=int(mix_batch[k][-1])
        j+=1
    x_train=[]
    x_test=[]
    y_train=[]
    y_test=[]
    for i in range(m):
        if m_c[i]==1:
            x_train.append(x_c[i])
            y_train.append(y_c[i])
        else:
            x_test.append(x_c[i])
            y_test.append(y_c[i])
    x_train=tf.convert_to_tensor(x_train)
    x_test=tf.convert_to_tensor(x_test)
    y_train=np.array(y_train)
    y_train=tf.convert_to_tensor(y_train)
    y_test=np.array(y_test)
    y_test=tf.convert_to_tensor(y_test)
    m_true=np.zeros(m)
    m_true[:count_member]=1
    return (x_train,y_train),(x_test,y_test),m_true

def loadData_cifar10():
    '''
    Attck the target with BLINDMI-DIFF-W, BLINDMI-DIFF with gernerated non-member.
    The non-member is generated by randomly chosen data and the number is 20 by default.
    If the data has been shuffled, please directly remove the process of shuffling.
    :param target_model: the model that will be attacked
    :param x_: the data that target model may used for trainisng
    :param y_true: the label of x_
    :param m_true: one of 0 and 1, which represents each of x_ has been trained or not.
    :param non_Mem_Generator: the method to generate the non-member data. The default non-member generator
    is Sobel.
    :return:  Tensor arrays of results
    '''
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)
    DATA_NAME = sys.argv[1] if len(sys.argv) > 1 else "CIFAR10"
    TARGET_MODEL_GENRE = sys.argv[2] if len(sys.argv) > 2 else "ResNet50"
    TARGET_WEIGHTS_PATH = "weights/Target/{}_{}.hdf5".format(DATA_NAME, TARGET_MODEL_GENRE)

    (x_train_tar, y_train_tar), (x_test_tar, y_test_tar), m_true = globals()['load_' + DATA_NAME]('TargetModel')
    x_=np.r_[x_train_tar,x_test_tar]
    y_true=np.r_[y_train_tar,y_test_tar]
    target_model = load_model(TARGET_WEIGHTS_PATH)

    y_pred=target_model.predict(x_)
    m,n=np.shape(y_pred)
    y_result=np.zeros((m,n))
    correct_index=[]
    correct_label=[]
    correct_pred=[]
    incorrect_index=[]
    incorrect_label=[]
    incorrect_pred=[]
    for i in range(m):
        interval=list(y_pred[i])
        index=interval.index(max(interval))
        y_result[i][index]=1
        true=list(y_true[i])
        true_index=true.index(max(true))
        if index==true_index:
            correct_index.append(i)
            correct_label.append(y_true[i])
            correct_pred.append(y_pred[i])
        else:
            incorrect_index.append(i)
            incorrect_label.append(y_true[i])
            incorrect_pred.append(y_pred[i])
    correct_pred=tf.convert_to_tensor(correct_pred)
    incorrect_pred=tf.convert_to_tensor(incorrect_pred)
    correct=tf.convert_to_tensor(np.c_[correct_pred[y_true[correct_index].astype(bool)],
                                        np.sort(correct_pred, axis=1)[:, ::-1][:, :2]])
    incorrect=tf.convert_to_tensor(np.c_[incorrect_pred[y_true[incorrect_index].astype(bool)],
                                        np.sort(incorrect_pred, axis=1)[:, ::-1][:, :2]])
#    incorrect_read=pd.DataFrame(incorrect_index)
#    incorrect_read.to_excel('incorrect.xlsx')
    mix = np.c_[y_pred[y_true.astype(bool)], np.sort(y_pred, axis=1)[:, ::-1][:, :2]]  #所有数据变换后的结果
    mix=mix.tolist()
    for i in range(m):
        mix[i].append(i)
    mix=tf.convert_to_tensor(mix)
    tf.random.set_seed(1)
    nonMem_index =[18631 , 8342 ,18939,  4859,  7038, 11781, 17532 , 7138,  5440, 16036,  7465 ,16952,6267  , 672 ,19181 ,13813 , 1432 ,  425, 16173 ,11005]
    #nonMem_index = np.random.randint(0, x_.shape[0], size=20)  # 随机生成
    Mem_dataset=[]
    Mem_index=[]
    for i in range(m):
        if m_true[i]==1:
            Mem_dataset.append(x_[i])
            Mem_index.append(i)
    Mem_dataset=tf.convert_to_tensor(Mem_dataset)
    Mem_pred=target_model.predict(Mem_dataset)
    Mem=tf.convert_to_tensor(np.c_[Mem_pred[y_true[Mem_index].astype(bool)],
                                        np.sort(Mem_pred, axis=1)[:, ::-1][:, :2]])
    tf.random.set_seed(1)
    data = tf.data.Dataset.from_tensor_slices((mix, m_true)).shuffle(buffer_size=x_.shape[0]).\
        batch(20).prefetch(tf.data.experimental.AUTOTUNE)  #切分mix为20000个10列的tensor，每个数据集有20个样本

    x_c=tf.constant(0, shape=(160, 32, 32, 3))
    x_c= np.array(x_)
    y_c = np.ones((160, 10))
    m_c = np.ones(160)
    i=0
    j=0
    idx=pd.read_excel('construct/cifar10_c_u1.xlsx')
    idx = np.array(idx)[:]
    for (mix_batch, m_true_batch) in data:  #min_batch:x  m_true_batch:是否为成员
        if j in idx:
            for k in range(20):
                p=int(mix_batch[k][-1])
                x_c[i]=x_[p]
                y_c[i]=y_true[p]
                m_c[i]=int(m_true_batch[k])
                i+=1
        j+=1
    x_train=[]
    x_test=[]
    y_train=[]
    y_test=[]
    for i in range(160):
        if m_c[i]==1:
            x_train.append(x_c[i])
            y_train.append(y_c[i])
        else:
            x_test.append(x_c[i])
            y_test.append(y_c[i])
    x_train=tf.convert_to_tensor(x_train)
    x_test=tf.convert_to_tensor(x_test)
    y_train=np.array(y_train)
    y_train=tf.convert_to_tensor(y_train)
    y_test=np.array(y_test)
    y_test=tf.convert_to_tensor(y_test)
    m_true=np.zeros(160)
    m_true[:80]=1
    return (x_train,y_train),(x_test,y_test),m_true

def loadData_CH_MNIST():
    '''
    Attck the target with BLINDMI-DIFF-W, BLINDMI-DIFF with gernerated non-member.
    The non-member is generated by randomly chosen data and the number is 20 by default.
    If the data has been shuffled, please directly remove the process of shuffling.
    :param target_model: the model that will be attacked
    :param x_: the data that target model may used for trainisng
    :param y_true: the label of x_
    :param m_true: one of 0 and 1, which represents each of x_ has been trained or not.
    :param non_Mem_Generator: the method to generate the non-member data. The default non-member generator
    is Sobel.
    :return:  Tensor arrays of results
    '''
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)
    DATA_NAME = sys.argv[1] if len(sys.argv) > 1 else "CH_MNIST"
    TARGET_MODEL_GENRE = sys.argv[2] if len(sys.argv) > 2 else "ResNet50"
    TARGET_WEIGHTS_PATH = "weights/Target/{}_{}.hdf5".format(DATA_NAME, TARGET_MODEL_GENRE)

    (x_train_tar, y_train_tar), (x_test_tar, y_test_tar), m_true = globals()['load_' + DATA_NAME]('TargetModel')
    x_=np.r_[x_train_tar,x_test_tar]
    y_true=np.r_[y_train_tar,y_test_tar]
    target_model = load_model(TARGET_WEIGHTS_PATH)

    y_pred=target_model.predict(x_)
    m,n=np.shape(y_pred)
    y_result=np.zeros((m,n))
    correct_index=[]
    correct_label=[]
    correct_pred=[]
    incorrect_index=[]
    incorrect_label=[]
    incorrect_pred=[]
    for i in range(m):
        interval=list(y_pred[i])
        index=interval.index(max(interval))
        y_result[i][index]=1
        true=list(y_true[i])
        true_index=true.index(max(true))
        if index==true_index:
            correct_index.append(i)
            correct_label.append(y_true[i])
            correct_pred.append(y_pred[i])
        else:
            incorrect_index.append(i)
            incorrect_label.append(y_true[i])
            incorrect_pred.append(y_pred[i])
    correct_pred=tf.convert_to_tensor(correct_pred)
    incorrect_pred=tf.convert_to_tensor(incorrect_pred)
    correct=tf.convert_to_tensor(np.c_[correct_pred[y_true[correct_index].astype(bool)],
                                        np.sort(correct_pred, axis=1)[:, ::-1][:, :2]])
    incorrect=tf.convert_to_tensor(np.c_[incorrect_pred[y_true[incorrect_index].astype(bool)],
                                        np.sort(incorrect_pred, axis=1)[:, ::-1][:, :2]])
#    incorrect_read=pd.DataFrame(incorrect_index)
#    incorrect_read.to_excel('incorrect.xlsx')
    mix = np.c_[y_pred[y_true.astype(bool)], np.sort(y_pred, axis=1)[:, ::-1][:, :2]]  #所有数据变换后的结果
    mix=mix.tolist()
    for i in range(m):
        mix[i].append(i)
    mix=tf.convert_to_tensor(mix)
    tf.random.set_seed(1)
    nonMem_index=[3439 ,2384 ,2494 , 291 ,  24 ,3600 ,1080 ,4858, 2535 ,1821 ,1518 ,3212 ,4546 ,2869,1698, 1165 ,2620 , 414 ,1153 ,4298]    #nonMem_index = np.random.randint(0, x_.shape[0], size=20)  # 随机生成
    Mem_dataset=[]
    Mem_index=[]
    for i in range(m):
        if m_true[i]==1:
            Mem_dataset.append(x_[i])
            Mem_index.append(i)
    Mem_dataset=tf.convert_to_tensor(Mem_dataset)
    Mem_pred=target_model.predict(Mem_dataset)
    Mem=tf.convert_to_tensor(np.c_[Mem_pred[y_true[Mem_index].astype(bool)],
                                        np.sort(Mem_pred, axis=1)[:, ::-1][:, :2]])
    tf.random.set_seed(2)
    data = tf.data.Dataset.from_tensor_slices((mix, m_true)).shuffle(buffer_size=x_.shape[0]).\
        batch(20).prefetch(tf.data.experimental.AUTOTUNE)  #切分mix为20000个10列的tensor，每个数据集有20个样本

    x_c=tf.constant(0, shape=(620, 32, 32, 3))
    x_c= np.array(x_)
    y_c = np.ones((620, 8))
    m_c = np.ones(620)
    i=0
    j=0
    idx=pd.read_excel('construct/CH_MNIST_c_u1.xlsx')
    idx = np.array(idx)[:]

    for (mix_batch, m_true_batch) in data:  #min_batch:x  m_true_batch:是否为成员
        if j in idx:
            for k in range(20):
                p=int(mix_batch[k][-1])
                x_c[i]=x_[p]
                y_c[i]=y_true[p]
                m_c[i]=int(m_true_batch[k])
                i+=1
        j+=1
    x_train=[]
    x_test=[]
    y_train=[]
    y_test=[]
    for i in range(620):
        if m_c[i]==1:
            x_train.append(x_c[i])
            y_train.append(y_c[i])
        else:
            x_test.append(x_c[i])
            y_test.append(y_c[i])
    x_train=tf.convert_to_tensor(x_train)
    x_test=tf.convert_to_tensor(x_test)
    y_train=np.array(y_train)
    y_train=tf.convert_to_tensor(y_train)
    y_test=np.array(y_test)
    y_test=tf.convert_to_tensor(y_test)
    m_true=np.zeros(620)
    m_true[:310]=1
    return (x_train,y_train),(x_test,y_test),m_true

def loadData_imagenet():
    '''
    Attck the target with BLINDMI-DIFF-W, BLINDMI-DIFF with gernerated non-member.
    The non-member is generated by randomly chosen data and the number is 20 by default.
    If the data has been shuffled, please directly remove the process of shuffling.
    :param target_model: the model that will be attacked
    :param x_: the data that target model may used for trainisng
    :param y_true: the label of x_
    :param m_true: one of 0 and 1, which represents each of x_ has been trained or not.
    :param non_Mem_Generator: the method to generate the non-member data. The default non-member generator
    is Sobel.
    :return:  Tensor arrays of results
    '''
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)
    DATA_NAME = sys.argv[1] if len(sys.argv) > 1 else "imagenet"
    TARGET_MODEL_GENRE = sys.argv[2] if len(sys.argv) > 2 else "ResNet50"
    TARGET_WEIGHTS_PATH = "weights/Target/{}_{}.hdf5".format(DATA_NAME, TARGET_MODEL_GENRE)

    (x_train_tar, y_train_tar), (x_test_tar, y_test_tar), m_true = globals()['load_' + DATA_NAME]('TargetModel')
    x_=np.r_[x_train_tar,x_test_tar]
    y_true=np.r_[y_train_tar,y_test_tar]
    target_model = load_model(TARGET_WEIGHTS_PATH)

    y_pred=target_model.predict(x_)
    m,n=np.shape(y_pred)
    y_result=np.zeros((m,n))
    correct_index=[]
    correct_label=[]
    correct_pred=[]
    incorrect_index=[]
    incorrect_label=[]
    incorrect_pred=[]
    for i in range(m):
        interval=list(y_pred[i])
        index=interval.index(max(interval))
        y_result[i][index]=1
        true=list(y_true[i])
        true_index=true.index(max(true))
        if index==true_index:
            correct_index.append(i)
            correct_label.append(y_true[i])
            correct_pred.append(y_pred[i])
        else:
            incorrect_index.append(i)
            incorrect_label.append(y_true[i])
            incorrect_pred.append(y_pred[i])
    correct_pred=tf.convert_to_tensor(correct_pred)
    incorrect_pred=tf.convert_to_tensor(incorrect_pred)
    correct=tf.convert_to_tensor(np.c_[correct_pred[y_true[correct_index].astype(bool)],
                                        np.sort(correct_pred, axis=1)[:, ::-1][:, :2]])
    incorrect=tf.convert_to_tensor(np.c_[incorrect_pred[y_true[incorrect_index].astype(bool)],
                                        np.sort(incorrect_pred, axis=1)[:, ::-1][:, :2]])
#    incorrect_read=pd.DataFrame(incorrect_index)
#    incorrect_read.to_excel('incorrect.xlsx')
    mix = np.c_[y_pred[y_true.astype(bool)], np.sort(y_pred, axis=1)[:, ::-1][:, :2]]  #所有数据变换后的结果
    mix=mix.tolist()
    for i in range(m):
        mix[i].append(i)
    mix=tf.convert_to_tensor(mix)
    tf.random.set_seed(1)
    nonMem_index=[ 9195, 18317, 14103 , 6464 , 2302 ,13525 ,13077, 16878 ,12130 ,15065, 17800, 12089,2149,  2389 ,17830, 14248  ,8993 ,11963 , 8142 , 4365]
    Mem_dataset=[]
    Mem_index=[]
    for i in range(m):
        if m_true[i]==1:
            Mem_dataset.append(x_[i])
            Mem_index.append(i)
    Mem_dataset=tf.convert_to_tensor(Mem_dataset)
    Mem_pred=target_model.predict(Mem_dataset)
    Mem=tf.convert_to_tensor(np.c_[Mem_pred[y_true[Mem_index].astype(bool)],
                                        np.sort(Mem_pred, axis=1)[:, ::-1][:, :2]])
    tf.random.set_seed(1)
    data = tf.data.Dataset.from_tensor_slices((mix, m_true)).shuffle(buffer_size=x_.shape[0]).\
        batch(20).prefetch(tf.data.experimental.AUTOTUNE)  #切分mix为20000个10列的tensor，每个数据集有20个样本

    x_c=tf.constant(0, shape=(500, 32, 32, 3))
    x_c= np.array(x_)
    y_c = np.ones((500, 200))
    m_c = np.ones(500)
    i=0
    j=0
    idx=pd.read_excel('construct/imagenet_c_u1.xlsx')
    idx = np.array(idx)[:]

    for (mix_batch, m_true_batch) in data:  #min_batch:x  m_true_batch:是否为成员
        if j in idx:
            for k in range(20):
                p=int(mix_batch[k][-1])
                x_c[i]=x_[p]
                y_c[i]=y_true[p]
                m_c[i]=int(m_true_batch[k])
                i+=1
        j+=1
    x_train=[]
    x_test=[]
    y_train=[]
    y_test=[]
    for i in range(500):
        if m_c[i]==1:
            x_train.append(x_c[i])
            y_train.append(y_c[i])
        else:
            x_test.append(x_c[i])
            y_test.append(y_c[i])
    x_train=tf.convert_to_tensor(x_train)
    x_test=tf.convert_to_tensor(x_test)
    y_train=np.array(y_train)
    y_train=tf.convert_to_tensor(y_train)
    y_test=np.array(y_test)
    y_test=tf.convert_to_tensor(y_test)
    m_true=np.zeros(500)
    m_true[:250]=1
    return (x_train,y_train),(x_test,y_test),m_true